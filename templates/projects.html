  <div class="row">
    <h2>Projects</h2>
    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://evalai.cloudcv.org">EvalAI</a>: Evaluating state of the art in AI</h3>
        <p>Open source platform to create, collaborate and participate in the AI Challenges organized around the globe.</p>
        <a class="github-button btn" href="https://github.com/cloud-cv/evalai" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
        <a class="github-button" href="https://github.com/cloud-cv/evalai" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
        <a class="github-button" href="https://github.com/cloud-cv/evalai/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a>
      </div>
    </div>

    <div class="row">
      <div class="col-sm-4">
        <a href="https://evalai.cloudcv.org" target="_blank"><img src="/static/img/evalai_preview.png" width="100%"></a>
      </div>
      <div class="col-sm-4">
        <img src="/static/img/kaggle_comparison.png" width="100%">
      </div>
      <div class="col-sm-4" align="center">
        <h5>Invited talk on EvalAI in VQA 2017 Workshop</h5>
        <iframe width="100%" height="200px" src="https://www.youtube.com/embed/goEe4gx1yZg?rel=0&amp;showinfo=0;start=1682" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>

    <hr>

    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://fabrik.cloudcv.org">Fabrik</a>: Collaboratively build, visualize, and design neural nets in browser</h3>
          <p class="content">Fabrik is an online collaborative platform to build, visualize and train deep learning models via a simple drag-and-drop interface. </p>
          <a class="github-button btn" href="https://github.com/cloud-cv/fabrik" data-size="large" data-show-count="false" aria-label="cloud-cv/fabrik on GitHub">Code</a>
          <a class="github-button" href="https://github.com/cloud-cv/fabrik" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/fabrik on GitHub">Star</a>
          <a class="github-button" href="https://github.com/cloud-cv/fabrik/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/fabrik on GitHub">Fork</a>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-6">
        <img src="/static/img/fabrik.gif" width="100%">
      </div>
      <div class="col-sm-6" align="center">
        <iframe width="100%" height="300px" src="https://www.youtube.com/embed/woZ8XFZ4rMc?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>

    <hr>

    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://visualchatbot.cloudcv.org">Visual Chatbot</a>: A chatbot that can see!</h3>
          <p class="content">Built a visual chatbot which can hold a meaningful dialog with humans natural, conversational language about visual content. Specifically, given an image, a dialog history, and a question about the image, the chatbot has to ground the question in image, infer context from history, and answer the question accurately.</p>
          <a class="github-button btn" href="https://github.com/cloud-cv/visual-chatbot" data-size="large" data-show-count="false" aria-label="cloud-cv/visual-chatbot on GitHub">Code</a>
          <a class="github-button" href="https://github.com/cloud-cv/visual-chatbot" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/visual-chatbot on GitHub">Star</a>
          <a class="github-button" href="https://github.com/cloud-cv/visual-chatbot/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/visual-chatbot on GitHub">Fork</a>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-4" align="center">
        <h3>Live Demo</h3>
        <iframe style="border: groove;" src="https://visualchatbot.cloudcv.org" width="100%" height="530" frameborder="0" allowfullscreen></iframe>
      </div>
      <div class="col-sm-8" align="center">
        <h3>Demo Video</h3>
        <iframe width="100%" height="530" src="https://www.youtube.com/embed/SztC8VOWwRQ?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>        

    <hr>

    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://vqa.cloudcv.org">Visual Question Answering (VQA) </a>Demo</h3>
          <p class="content">In Visual Question Answering, given an image and a free-form natural language question about the image (e.g., "What kindof store is this?", "How many people are waiting in the queue?", "Is it safe to cross the street?") the model's task is to automatically produce a concise, accurate, free-form, natural language answer ("bakery", "5", "Yes"). This demo is implemented using <a href="https://github.com/jiasenlu/HieCoAttenVQA">Hierarchical Question-Image Co-Attention</a> model.</p>
          <a class="github-button btn" href="https://github.com/cloud-cv/vqa" data-size="large" data-show-count="false" aria-label="cloud-cv/vqa on GitHub">Code</a>
          <a class="github-button" href="https://github.com/cloud-cv/vqa" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/vqa on GitHub">Star</a>
          <a class="github-button" href="https://github.com/cloud-cv/vqa/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/vqa on GitHub">Fork</a>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-6" align="center">
        <h3>Live Demo</h3>
        <a href="http://vqa.cloudcv.org" target="_blank"><img src="/static/img/vqa.png" width="100%"></a>
      </div>
      <div class="col-sm-6" align="center">
        <iframe width="100%" height="250" src="https://www.youtube.com/embed/bC2kwzdyJPs?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>

    <hr>

    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://gradcam.cloudcv.org">Gradient-weighted Class Activation Mapping (Grad-CAM)</a> Demo</h3>
          <p class="content">Gradient-weighted Class Activation Mapping (Grad-CAM) is a novel class-discriminative localization technique, that can be used to make CNN based models interpretable. Grad-CAM highlights regions of the image the VQA model looks at while making predictions. Given an image and a caption or question about that image, the model shows where it looked while doing prediction.</p>
          <a class="github-button btn" href="https://github.com/cloud-cv/grad-cam" data-size="large" data-show-count="false" aria-label="cloud-cv/grad-cam on GitHub">Code</a>
          <a class="github-button" href="https://github.com/cloud-cv/grad-cam" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/grad-cam on GitHub">Star</a>
          <a class="github-button" href="https://github.com/cloud-cv/grad-cam/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/grad-cam on GitHub">Fork</a>
      </div>
    </div>

    <div class="row" align="center">
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/vqa">Grad-CAM VQA Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/vqa"><img src="/static/img/gcam_vqa.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/classification">Grad-CAM Classification Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/classification"><img src="/static/img/gcam_classification.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/captioning">Grad-CAM Captioning Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/captioning"><img src="/static/img/gcam_captioning.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4>Grad-CAM Demo Video</h4>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/COjUB9Izk6E?start=29" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>

    <hr>

    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://origami.cloudcv.org">Origami</a>: Artificial Intelligence as a Service</h3>
          <p class="content">Origami is an AI-as-a-service that allows researchers to easily convert their deep learning models into an online service that is widely accessible to everyone without the need to setup the infrastructure, resolve the dependencies, and build a web service around the deep learning model.</p>
          <a class="github-button btn" href="https://github.com/cloud-cv/origami" data-size="large" data-show-count="false" aria-label="cloud-cv/origami on GitHub">Code</a>
          <a class="github-button" href="https://github.com/cloud-cv/origami" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/origami on GitHub">Star</a>
          <a class="github-button" href="https://github.com/cloud-cv/origami/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/origami on GitHub">Fork</a>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-6">
        <img src="/static/img/origami.png" width="100%">
      </div>
      <div class="col-sm-6" align="center">
        <iframe width="100%" height="350" src="https://www.youtube.com/embed/wBM7YvcQiJQ?rel=0&amp;controls=0&amp;showinfo=0&amp;start=205" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
    </div>

    <hr>

    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://dbs.cloudcv.org">Diverse Beam Search </a>Demo</h3>
          <p class="content">Beam search, the standard work-horse for decoding outputs from neural sequence models like RNNs produces generic and uninteresting sequences. This is inadequate for AI tasks with inherent ambiguity — for example, there can be multiple correct ways of describing the contents of an image. The demo overcomes this by proposing a diversity-promoting replacement, <em>Diverse Beam Search</em> that produces sequences that are significantly different — with runtime and memory requirements comparable to beam search.</p>
          <a class="github-button btn" href="https://github.com/cloud-cv/diverse-beam-search" data-size="large" data-show-count="false" aria-label="cloud-cv/diverse-beam-search on GitHub">Code</a>
          <a class="github-button" href="https://github.com/cloud-cv/diverse-beam-search" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/diverse-beam-search on GitHub">Star</a>
          <a class="github-button" href="https://github.com/cloud-cv/diverse-beam-search/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/diverse-beam-search on GitHub">Fork</a>
      </div>
    </div>

    <div class="row" align="center">
      <div class="col-sm-5">
        <h4><a href="http://dbs.cloudcv.org/captioning" target="_blank">Live Demo</a></h4>
        <a href="http://dbs.cloudcv.org/captioning" target="_blank"><img src="/static/img/dbs.gif" width="100%"></a>
      </div>
      <div class="col-sm-7">
        <br><br><br>
        <a href="http://dbs.cloudcv.org/" target="_blank"><img src="/static/img/dbs_teaser.png" width="100%"></a>
      </div>
    </div>

    <hr>

    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"> <a target="_blank" href="http://210.212.85.155">JSS InfoConnect</a></h3>
          <p class="content">Web based application that acts as a medium for interaction between all students, faculties and management of JSSATE Noida college. Officially recognized by college. Serves 10,000+ requests per day, 20,000+ users, 20,000+ notices uploaded.</p>
          <a class="github-button btn" href="https://github.com/ncs-jss/http_200" data-size="large" data-show-count="false" aria-label="ncs-jss/http_200 on GitHub">Code</a>
          <a class="github-button" href="https://github.com/ncs-jss/http_200" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star ncs-jss/http_200 on GitHub">Star</a>
          <a class="github-button" href="https://github.com/ncs-jss/http_200/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork ncs-jss/http_200 on GitHub">Fork</a>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-6" align="center">
        <a href="http://210.212.85.155/" target="_blank"><img src="/static/img/infoconnect.png" width="100%"></a>
      </div>  
      <div class="col-sm-6" align="center">
        <a href="http://210.212.85.155/" target="_blank"><img src="/static/img/infoconnect1.png" width="100%"></a>
      </div>      
    </div>
    <hr>
  </div>
