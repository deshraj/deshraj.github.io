  <div class="row">
    <div class="col-md-12">
      <h2>Projects</h2>
      <hr>
    </div>
    <div class="col-md-12">
      <h3 class="content_heading"><a target="_blank" href="http://evalai.cloudcv.org">EvalAI</a>: Evaluating state of
        the art in AI</h3>
      <br>
      <p>Open source platform to create, collaborate and participate in the AI Challenges organized around the globe.
      </p>
      <a class="github-button btn" href="https://github.com/cloud-cv/evalai" data-size="large" data-show-count="false"
        aria-label="cloud-cv/evalai on GitHub">Code</a>
      <a class="github-button" href="https://github.com/cloud-cv/evalai" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
      <a class="github-button" href="https://github.com/cloud-cv/evalai/fork" data-icon="octicon-repo-forked"
        data-size="large" data-show-count="true" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-8">
      <a href="https://evalai.cloudcv.org" target="_blank"><img src="/static/img/evalai_preview.png" width="100%"></a>
    </div>
    <div class="col-md-4">
      <h5>Invited talk on EvalAI in VQA 2017 Workshop</h5>
      <iframe width="100%" height="200px"
        src="https://www.youtube.com/embed/goEe4gx1yZg?rel=0&amp;showinfo=0;start=1682" frameborder="0"
        allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
  </div>

  <hr>
  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading">HIEME: Human-Interactive Evaluation Made Easy</h3>
      <br>
      <p>Proof of concept of a central, standardized open source platform for human-in-the-loop evaluation of AI
        agents.
        Developed the infrastructure to pair Amazon Mechanical Turk (AMT) users in real-time with artificial visual
        dialog agents.</p>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-6">
      <h5>HIEME Architecture</h5>
      <img src="/static/img/hieme.jpeg" alt="HIEME" width="100%" height="400px">
    </div>
    <div class="col-md-6">
      <h5>Short Video on evaluating Visual Dialog Agents using HIEME</h5>
      <iframe width="100%" height="315" src="https://www.youtube.com/embed/HCpQWGmdyoY?rel=0" frameborder="0"
        allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
  </div>

  <hr>

  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading"><a target="_blank" href="http://fabrik.cloudcv.org">Fabrik</a>: Collaboratively
        build, visualize, and design neural nets in browser</h3>
      <br>
      <p>Fabrik is an online collaborative platform to build, visualize and train deep learning models via a simple
        drag-and-drop interface.</p>
      <a class="github-button btn" href="https://github.com/cloud-cv/fabrik" data-size="large" data-show-count="false"
        aria-label="cloud-cv/fabrik on GitHub">Code</a>
      <a class="github-button" href="https://github.com/cloud-cv/fabrik" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star cloud-cv/fabrik on GitHub">Star</a>
      <a class="github-button" href="https://github.com/cloud-cv/fabrik/fork" data-icon="octicon-repo-forked"
        data-size="large" data-show-count="true" aria-label="Fork cloud-cv/fabrik on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-6">
      <img src="/static/img/fabrik.gif" width="100%">
    </div>
    <div class="col-md-6">
      <iframe width="100%" height="300px"
        src="https://www.youtube.com/embed/woZ8XFZ4rMc?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0"
        allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
  </div>

  <hr>

  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading"><a target="_blank" href="http://demo-visualdialog.cloudcv.org/">Visual Chatbot</a>: A
        chatbot that can see!</h3>
      <br>
      <p>Built a visual chatbot which can hold a meaningful dialog with humans natural, conversational language about
        visual content. Specifically, given an image, a dialog history, and a question about the image, the chatbot
        has to ground the question in image, infer context from history, and answer the question accurately.</p>
      <a class="github-button btn" href="https://github.com/cloud-cv/visual-chatbot" data-size="large"
        data-show-count="false" aria-label="cloud-cv/visual-chatbot on GitHub">Code</a>
      <a class="github-button" href="https://github.com/cloud-cv/visual-chatbot" data-icon="octicon-star"
        data-size="large" data-show-count="true" aria-label="Star cloud-cv/visual-chatbot on GitHub">Star</a>
      <a class="github-button" href="https://github.com/cloud-cv/visual-chatbot/fork" data-icon="octicon-repo-forked"
        data-size="large" data-show-count="true" aria-label="Fork cloud-cv/visual-chatbot on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-8">
      <h3>Demo Video</h3>
      <iframe width="100%" height="400"
        src="https://www.youtube.com/embed/SztC8VOWwRQ?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0"
        allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
  </div>

  <hr>

  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading"><a target="_blank" href="http://vqa.cloudcv.org">Visual Question Answering (VQA)
        </a>Demo</h3>
      <br>
      <p>In Visual Question Answering, given an image and a free-form natural language question about the image (e.g.,
        "What kindof store is this?", "How many people are waiting in the queue?", "Is it safe to cross the street?")
        the model's task is to automatically produce a concise, accurate, free-form, natural language answer
        ("bakery", "5", "Yes"). This demo is implemented using <a
          href="https://github.com/jiasenlu/HieCoAttenVQA">Hierarchical Question-Image Co-Attention</a> model.</p>
      <a class="github-button btn" href="https://github.com/cloud-cv/vqa" data-size="large" data-show-count="false"
        aria-label="cloud-cv/vqa on GitHub">Code</a>
      <a class="github-button" href="https://github.com/cloud-cv/vqa" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star cloud-cv/vqa on GitHub">Star</a>
      <a class="github-button" href="https://github.com/cloud-cv/vqa/fork" data-icon="octicon-repo-forked"
        data-size="large" data-show-count="true" aria-label="Fork cloud-cv/vqa on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-6">
      <h3><a href="http://vqa.cloudcv.org" target="_blank">Live Demo</a></h3>
      <a href="http://vqa.cloudcv.org" target="_blank"><img src="/static/img/vqa.png" width="100%"></a>
    </div>
    <div class="col-md-6">
      <iframe width="100%" height="250"
        src="https://www.youtube.com/embed/bC2kwzdyJPs?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0"
        allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
  </div>

  <hr>

  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading"><a target="_blank" href="http://gradcam.cloudcv.org">Gradient-weighted Class
          Activation Mapping (Grad-CAM)</a> Demo</h3>
      <br>
      <p>Gradient-weighted Class Activation Mapping (Grad-CAM) is a novel class-discriminative localization technique,
        that can be used to make CNN based models interpretable. Grad-CAM highlights regions of the image the VQA
        model looks at while making predictions. Given an image and a caption or question about that image, the model
        shows where it looked while doing prediction.</p>
      <a class="github-button btn" href="https://github.com/cloud-cv/grad-cam" data-size="large" data-show-count="false"
        aria-label="cloud-cv/grad-cam on GitHub">Code</a>
      <a class="github-button" href="https://github.com/cloud-cv/grad-cam" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star cloud-cv/grad-cam on GitHub">Star</a>
      <a class="github-button" href="https://github.com/cloud-cv/grad-cam/fork" data-icon="octicon-repo-forked"
        data-size="large" data-show-count="true" aria-label="Fork cloud-cv/grad-cam on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-6">
      <h4><a href="http://gradcam.cloudcv.org/vqa">Grad-CAM VQA Demo</a></h4>
      <a href="http://gradcam.cloudcv.org/vqa"><img src="/static/img/gcam_vqa.gif" width="100%"></a>
    </div>
    <div class="col-md-6">
      <h4><a href="http://gradcam.cloudcv.org/classification">Grad-CAM Classification Demo</a></h4>
      <a href="http://gradcam.cloudcv.org/classification"><img src="/static/img/gcam_classification.gif"
          width="100%"></a>
    </div>
    <div class="col-md-6">
      <h4><a href="http://gradcam.cloudcv.org/captioning">Grad-CAM Captioning Demo</a></h4>
      <a href="http://gradcam.cloudcv.org/captioning"><img src="/static/img/gcam_captioning.gif" width="100%"></a>
    </div>
    <div class="col-md-6">
      <h4>Grad-CAM Demo Video</h4>
      <iframe width="100%" height="315" src="https://www.youtube.com/embed/COjUB9Izk6E?start=29" frameborder="0"
        allowfullscreen></iframe>
    </div>
  </div>

  <hr>

  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading"><a target="_blank" href="http://origami.cloudcv.org">Origami</a>: Artificial
        Intelligence as a Service</h3>
      <br>
      <p>Origami is an AI-as-a-service that allows researchers to easily convert their deep learning models into an
        online service that is widely accessible to everyone without the need to setup the infrastructure, resolve the
        dependencies, and build a web service around the deep learning model.</p>
      <a class="github-button btn" href="https://github.com/cloud-cv/origami" data-size="large" data-show-count="false"
        aria-label="cloud-cv/origami on GitHub">Code</a>
      <a class="github-button" href="https://github.com/cloud-cv/origami" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star cloud-cv/origami on GitHub">Star</a>
      <a class="github-button" href="https://github.com/cloud-cv/origami/fork" data-icon="octicon-repo-forked"
        data-size="large" data-show-count="true" aria-label="Fork cloud-cv/origami on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-6">
      <img src="/static/img/origami.png" width="100%">
    </div>
    <div class="col-md-6">
      <iframe width="100%" height="350"
        src="https://www.youtube.com/embed/wBM7YvcQiJQ?rel=0&amp;controls=0&amp;showinfo=0&amp;start=205"
        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>
  </div>

  <hr>

  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading"><a target="_blank" href="http://dbs.cloudcv.org">Diverse Beam Search </a>Demo</h3>
      <br>
      <p>Beam search, the standard work-horse for decoding outputs from neural sequence models like RNNs produces
        generic and uninteresting sequences. This is inadequate for AI tasks with inherent ambiguity — for example,
        there can be multiple correct ways of describing the contents of an image. The demo overcomes this by
        proposing a diversity-promoting replacement, <em>Diverse Beam Search</em> that produces sequences that are
        significantly different — with runtime and memory requirements comparable to beam search.</p>
      <a class="github-button btn" href="https://github.com/cloud-cv/diverse-beam-search" data-size="large"
        data-show-count="false" aria-label="cloud-cv/diverse-beam-search on GitHub">Code</a>
      <a class="github-button" href="https://github.com/cloud-cv/diverse-beam-search" data-icon="octicon-star"
        data-size="large" data-show-count="true" aria-label="Star cloud-cv/diverse-beam-search on GitHub">Star</a>
      <a class="github-button" href="https://github.com/cloud-cv/diverse-beam-search/fork"
        data-icon="octicon-repo-forked" data-size="large" data-show-count="true"
        aria-label="Fork cloud-cv/diverse-beam-search on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-5">
      <h4><a href="http://dbs.cloudcv.org/captioning" target="_blank">Live Demo</a></h4>
      <a href="http://dbs.cloudcv.org/captioning" target="_blank"><img src="/static/img/dbs.gif" width="100%"></a>
    </div>
    <div class="col-md-7">
      <br><br><br>
      <a href="http://dbs.cloudcv.org/" target="_blank"><img src="/static/img/dbs_teaser.png" width="100%"></a>
    </div>
  </div>

  <hr>

  <div class="row">
    <div class="col-md-12">
      <h3 class="content_heading"> <a target="_blank" href="http://210.212.85.155">JSS InfoConnect</a></h3>
      <br>
      <p>Web based application that acts as a medium for interaction between all students, faculties and management of
        JSSATE Noida college. Officially recognized by college. Serves 10,000+ requests per day, 20,000+ users,
        20,000+ notices uploaded.</p>
      <a class="github-button btn" href="https://github.com/ncs-jss/http_200" data-size="large" data-show-count="false"
        aria-label="ncs-jss/http_200 on GitHub">Code</a>
      <a class="github-button" href="https://github.com/ncs-jss/http_200" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star ncs-jss/http_200 on GitHub">Star</a>
      <a class="github-button" href="https://github.com/ncs-jss/http_200/fork" data-icon="octicon-repo-forked"
        data-size="large" data-show-count="true" aria-label="Fork ncs-jss/http_200 on GitHub">Fork</a>
    </div>
  </div>
  <br>
  <div class="row">
    <div class="col-md-6">
      <a href="http://210.212.85.155/" target="_blank"><img src="/static/img/infoconnect.png" width="100%"></a>
    </div>
    <div class="col-md-6">
      <a href="http://210.212.85.155/" target="_blank"><img src="/static/img/infoconnect1.png" width="100%"></a>
    </div>
  </div>
  <hr>
  </div>
